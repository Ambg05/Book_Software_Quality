## Making random changes

Any code change that is not confirmed by a Test [^test] is a random change with non-deterministic results.

Making a code change that does not result in a test breaking (somewhere), means that the current test infrastructure is not good enough.

The reality is that the programmer after making changes will eventually check them. Maybe it is by opening up a webpage/app, making a Postman/curl request, clicking on links/buttons, looking at an UI, etc...

The problem is these checks are manual, non-repeatable and non-comprehensive checks. Even worse, what gets checked tends to be reduced with each interaction, since the human brain really doesn't like to repeat actions that produce the same results, and the developer naturally wants to check the consequences of the latest changes (not everything that could occur on that particular situation).

Without running these checks in a programmatically and repeated way (i.e. a Test), what happens is that the real coverage of the changes made are not correctly understood.

And if it is bad for the developer who made the changes to understand the side-effect of its changes, it is even worse for the QA team. How are they supposed to check the consequences of the latest code changes, if they are not able to get a full and detailed picture of the side effects.

Of course that just because a test broke, that doesn't mean that the code changes are being correctly tested or understood. In fact what is really interesting are the cases when the test that one would expect to break still passes, and another one (originally not related) is the one that fails. This either means that the fix was done in the wrong location, or that the impact of the change is happening at a different place (with both scenarios requiring further investigation).

Another sign that something is not right, is when simple code changes that should require simple test changes, do actually require considerable time to make the fix the tests that broke. What this means is that the tests are currently fragile and a refactoring (of the tests) is needed.

The reality is that making code changes without Tests is equivalent to making random changes and hoping that one of them does actually have the expected result [^hope], and that there are no major side effects. These 'non detected during development' side-effects (major or minor) will eventually affect the end-users:

  - who will report a bug,
  - which will be allocated for fix,
  - which when coded will not be fully tested,
  - which will create more 'non detected during development' side-effects

Creating the never-ending bug parade that affects most applications these days.


[^test]: A test executed by an test framework in a way that is repeatable and reproducible
[^hope]: Can also be called HTT - Hope Driven Development

### Code Coverage changes are part of the test success criteria

Broken tests are a great signal of side-effects of code changes, but an even better metric is changes in code coverage.

One of the reasons why 100% code coverage is so important, is because it provides accurate feedback on the impact of code changes. The lower the code coverage percentage, the harder it is to understand and review what happened with the latest commits.

Ideally, 100% code coverage should be one of the success criteria for Continuous Delivery

All apps start with 100% code coverage (well, technically, infinite Code Coverage), but unfortunately, 0% Code Coverage is the default.

### Git commits should only have the code and tests for the worked issue

One of the powers of git is its ability to allow the user merging the Pull Requests (PRs) to require quality and focus from the user submitting the changes.

I> this is a power that should be encouraged to be used. This concept was part of the original Linus design

This means that instead of massive Git Commits and PRs, that are just about impossible to read, what should happen is clean and focused PRs which contain the affected code and tests (with links to the respective issue).

I> add info about rebase
I> add info about git history
I> related to 'Git for security' chapter

### Performing code reviews by reading the tests first

One of the great side effects of having code and test submitted in the same Pull Request (PR) is that it allows the review process to occur not by reading the code first and then the tests, but by reading the tests first.

What happens when the tests are read first, is that the reviewed builds a mental model of the code changes that are expected to occur. What is interesting is what happens when the code changes don't match the tests changes.

This could happen because there is not enough test coverable, which means that random changes where made

It could be because the tests are to fragile and there were too many tests changes when compared with the actual code changes.

Or it could be that the existing tests are not good enough, and the tests need improvement.

Just because a test needed to be changed, that doesn't mean that the code changes are being correctly tested. These reviews are an important part of ensuring the high quality of code and tests.

### Clicking are ephemeral tests [^ephemeral]

A significant amount of time is spent by developers, QA and managers in clicking on links and buttons.

All these clicks are of course tests. The problem is that they are ephemeral and disappear after each click.

The power of Tests is that they are not only automatically repeatable, they can be scheduled to occur at regular intervals and more importantly they will all execute (vs the human tester which will tend on only check/click on the perceived locations of the latests changes).

A good example is are the hundreds of permutations that occur on an user login system, where just the password recovery workflow requires dozens for highly specific Tests.


[^ephemeral]: Wikipedia definition (https://en.wikipedia.org/wiki/Ephemerality) Typically the term ephemeral is used to describe objects found in nature, although it can describe a wide range of things, including human artifacts intentionally made to last for only a temporary period, in order to increase their perceived aesthetic value.

### How much time of your life have you spent on checking your code changes

For example logging in into a site or staring an application.

What is shocking, is that even though the actually coverage and effectiveness of the checks done to code changes made is really low, those checks take significant amount of time to perform.

Here is a typical workflow of such development practices:

- make change to source code file
- save it (some IDE do this automatically)
- compile it (some IDEs and languages don't require this)
- deploy to test server (which ranges from automatically to minutes)
- move mouse to open browser
- go to page that has the change made and get it into the correct state (this can be a simple browser refresh, or might require multiple steps)
- trigger the changed behavior (created by the code change
- go back to the IDE, and start again

Even when some of this happens automatically due to the chosen IDE or technology, the developer will need to switch context and will lose the mental models created during development.

This means that even if this loop takes 20 secs (which is not that realistic, since this regularly  take minutes), the impact to the developer's concentration level is significant.

{note:find reference from Deep Work book on the name of these 'non measured costs'}

### Change of context, humans are not good at it

When a developer has to move focus from development (i.e. it's IDE), the productivity loss it much greater than the duration of that interruption.

These interruptions (maybe a colleague asking a question, an email that just arrived in the inbox or the execution of a manual test) result in the developer's mind needing to switch context, which is scientifically proven that we humans are not very good at.

The concept of Deep Work (add book reference) is about the power that occurs when we are able to work continuously with high focus. Another analogy is when a developer is in the 'zone'

When programing there are number of models and data that is uploaded to the developer's brain. These models represent the current code behavior and the desired changes. The more complex the application (or code change) the longer it takes to reach a state where the problem is correctly understood and changes visualized.

Changing context will impact these mental models and require their rebuild (after coming back to the code).

When developers need to manually test their code changes, the productivity impact is enormous.

It is recommended that for projects with weak Test infrastructure, the RISK 'Lack of tests makes the developers 20% inefficient' is added and marked to be accepted by the technical architect and business owner)

### A key requirement for Test infrastructure is to make developers productive

An effective test infrastructure and architecture has to be focused on making the developers more productive, code faster, refactor faster and replace IDE debugging as way to debug issues.

By making the developers more productive, we create an environment where developers will write the tests themselves. Not because they are being 'forced to', but because they have learned that those tests save them time, and allows them to deploy with confidence.

### 100% code coverage should be an effortless side-effect of development

When developers have real-time test execution and code coverage on the IDE, 100% code coverage will be an side-effect of coding.

When developers can see exactly what code paths are being executed (and what data reaches what code), the idea that code changes should not be tested becomes a weird occurrence, since no developer will write code is not checked (in one way or another).

This brings up back to the concept of simplicity and the fact that coding should be simple.

### Measure how much time developers actually spend coding

A good way to measure across teams their current efficiency level (and test productivity), is to look at how much time the developers actually spend on coding.

Ironically most developers don't spent a lot of time developing (i.e. writing code). Even if we just look at the time that developers are focused on coding (i.e. removing meetings and other related activities), unless there is a strong testing infrastructure in place (which the dev can access and execute), the actual time that is spend on writing code is small when compared with the manual process of testing it.

### Measure how many Pull Requests are sent across teams

A great metric to measure the testing infrastructure and collaboration culture is to look at the Pull Requests (PRs) that are sent between the multiple teams.

The idea is that teams should be communicating using PRs and Tests. Not only this will make the environment much more productive, it will promote cross-fertilization of ideas, workflows and knowledge.

The reason this matter for security is that usually the best place to fix a security issue is not on the layer where it was discovered. But if it is hard to make changes on other modules/teams, then the fix will tend to be done on the location where it is easier, not where it is more effective.

### Code debugging is a sign of bad Test technology

When a developer debugs code (in a debugger), the usual workflow is:
1. set a number of breakpoints (where the execution should stop)
2. run the app
3. navigate to the location where the breakpoint can be hit
4. on breakpoint hit, look at the local variables
5. if needed, step through the application

When doing this workflow, the question being asked is "What is the state of my application at Location X?"

Debugging is one way to answer that question, but not only it is an highly inefficient process, it is not repeatable and doesn't scale.

A much better workflow is achieved when we have a real-time test execution environment with real-time code coverage. In this environment not only the rest runs automatically, the code coverage will indicate the code paths, and simple debug messages can be used to monitor the variables values.

The lack of using the debugger is an interesting side effect of a powerful test environment.

### Feeding test execution data to ELK and visualizing it in real time

After ELK (or similar) technologies are supported by the application (with data points generated from the inside), and the developer is able to access the custom dashboards for all its commits (for all branches) on all dev environments (from local to QA to pre-prod), an very powerful development aid will materialize in front of the developer's eyes: the real-time visualization of tests executions.

What happens is that the developer very quickly learns what should be the expected shapes that the ELK graphs should be producing (based on past test executions). This provides very valuable feedback on the impact of the latest changes.

Of course that once this environment is in place, the developer will (without being asked or even thinking too hard about it) start writing better graphs, specifically designed to help him debug the bug/feature currently under development.

These custom views created by developers, can then be used by other teams, namely the QA and NOC.

What is more interesting are the subtle changes the developer makes (because he has easy access to the code), which are specifically designed to improve the quality of the data sent and visualized by ELK.

### Measuring release's stress

The level of stress, issues, events, fixes and time that releases take, is a great bechmark for the quality of the code and tests.

If the team ships on a Wednesday, and key members of the team need to be on call to deal with the regular issues that occur due to that release, then you have a problem with that team.

Not only deployments should occur everyday (or hour), they should have no side affects, and in the rare case when they need to be reset, the revert process should be smooth, fast and effective.

The faster the deployment, the smaller the change and the easier it is to refactor the application.

The easier it is to refactor the application, the easier it is to address code quality and security issues.

The team that is able to push into production on a Friday afternoon with full confidence that nobody is going to have to stay behind to clean up the mess, is the team that has been shipping code all week (into dev, qa, pre-prod) and knows that their changes work with production data

Measuring deployment stress is then a great way to identify the teams that need help in their test infrastructure and setup (which is one of the areas where DevOps make a massive difference)

### Writing non-tested code is cheaper in the short-term

It is import not to sugarcoat this. The reality is that in the short term, it is indeed cheaper and simpler to: _just make the change and we'll add the test later_ (which never really happens)

The weaker the test infrastructure (when it is hard to write tests) the more expensive and complicated it is to make changes that are fully tested.

It is important to take into account that in such environment, ever though it is highly inefficient for developers to write code without tests (when compared to writing with tests), it is still cheaper, when compared with the effort to having to figure out how to test a particular part of the code

This means that the reason developers don't write tests, is not because they don't want to, it is because at that moment in time, they would be required to resolve key components of the test infrastructure (for example: how to get to page XYZ, how to simulate a particular service, how to deal with inner framework calls which depend on objects that are harder to access)

The problem is that in the medium and long term, these short terms gains are more than lost by customer impact of bugs created, and effort required to fix them.

### Don't use main, use a test

### When the users tell you what you code did

### Story: One char that broke the sites

Tell story

### Story: Site that worked on QA, Pre and not live

Todo-Note:
 - find 'Making random changes' quote
