## Software Complexity

- Moore's law allow software (lack of) quality to hide under the (newly gained) speed
- 48k Spectrum and Amiga
- Enormous Java stack traces
- Inefficient algorithms (case study of finding SQL Injection via DB queries compilation analysis)
- Why does anything take more than milliseconds to execute (when we have processors that can run millions of instructions per second)
 - This is something that one can worry about when coding 100% Code Coverage and Real-time code execution (via tests)

### tending towards complexity

Software has a very hard property where it tends towards complexity

It is very easy to create it (software) but very hard to untangle

### Measuring Complexity

- tools like NDepend are great ways to measure Complexity
- measuring complexity is key for measuring quality
- the more complex a system is the harder it is to simplify it
- software is able to easy create complex solutions (which are hard or maybe even impossible to understand)
 - with crazy types of side effects

- JSFuck is a great example of software complexity
  - (add example of alert(42) in JSFuck)
  - add explanation of how it works
  - other examples of the power (and craziness) of Javascript see the 1k competitions
- Buffer overflows (in c/c++ code) shows how weak the building blocks of technology are (namely mixing code and data)

### Software evolution

- As Nature does it
- Resilient to catastrophic failures
- Failures are a good thing (part of evolution)
- Mutation is good

### Diagrams from code

Software architecture diagrams must come from code.

- Code and all supporting artifacts seen as a graph
- massaged programmatically to make sense and to allow difference types of analysis
- when you ask 'how does this work' and somebody starts drawing a diagram, you know you have a problem
 - specially when the diagram is not going to accurate or up-to-date
 - threat models can be used to solve this problem (where threat models become the source of truth)
- Analogy with 'attack surface mapping' question of 'how many doors exist in this building' or 'where is the latest version of the building architecture'

### Mapping attack surface

A good way to make the point of the need to have up-to-date diagrams is to ask for an Application's Attack surface

- the urls (or endpoints) are just the beginning
- also important are: data fields, authentication, authorization, resilience, data confidentiality requirements, etc..
  - Strings are particularly important
- Add diagram with example table that needs to be created (see early TM web services diagram)

### Banning Strings

- explain why strings needs to be banned
- strongly type classes are what we needs
- reference John W post to OWASP leaders (and research on this topic)

### High-frequency trading shows the power of small

- small incremental changes scale really fast and deliver real value (in this case on small transaction's charges or small profits)
- incremental changes is also how nature works

- an interesting question is if the great recession was created by technology (and not by corrupt and greedy bankers).
 - 'pure creatures of big computation' [^jl-p27]

 - part of the reason for the crash was a system based on "too much complexity, played by players that don't really understand how it works (just it's behavior)"
   - before the crash, the idea was that the system was too big to fail and would auto-correct itself
   - sounds just like software today, doesn't it?

[^jl-p27]: 'Who owns the future?', Jaron Lanier, p27

### Single process Firefox

The challenges faced by firefox to perform a 'medium complex' task like running each tab in its own process, is a good example of the practical problems of complexity, interconnectivity and refactoring

- chrome got there first (and many years ago)
- good example of how ideas are not that important (what matters is the execution)
- add info on how much security one gains from isolating tabs/websites in process
- isolating in process is just the first step
- real isolation is much harder (but very desirable)
- single process is another way of doing Sandboxing
- docker and containers are the natural evolution
- the irony with this lack of speed is that Firefox was born out of a major simplification of the mozilla browser (from Netscape). In a way somebody should Firefox Firefox.


### Application's behavior complexity

Real world app's complexity tends to be equivalent to the complexity of the code.

I had this epiphany when during a security review of an large Sharepoint deployment and realized that the complexity of the security permissions (i.e. who has access to what file/folder/project) was so great, that not only the client had lost control of it, custom tools and visualization were needed.

I realized I needed the equivalent of SAST technology (with users marked as sources and files marked as sinks) which would create traces that could then be analyzed for blind spots (i.e. users that should not have access to particular file)

This same problem also tends to occur with Active Directory and file/group permissions
