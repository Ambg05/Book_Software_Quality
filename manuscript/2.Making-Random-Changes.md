## Making random changes

Any code change that is not confirmed by a Test is a random change with non-deterministic results.

Making a code change that does not result in a test breaking (somewhere), means that the current test infrastructure is not good enough.

The reality is that the programmer after making changes will eventually check them. Maybe it is by opening up a webpage/app, making a Postman/curl request, clicking on links/buttons, looking at an UI, etc...

The problem is these checks are manual, non-repeatable and non-comprehensive checks. Even worse, what gets checked tends to be reduced with each interaction, since the human brain really doesn't like to repeat actions that produce the same results, and the developer naturally wants to check the consequences of the latest changes (not everything that could occur on that particular situation).

Without running these checks in a programmatically and repeated way (i.e. a Test), what happens is that the real coverage of the changes made are not correctly understood.

And if it is bad for the developer who made the changes to understand the side-effect of its changes, it is even worse for the QA team. How are they supposed to check the consequences of the latest code changes, if they are not able to get a full and detailed picture of the side effects.

Of course that just because a test broke, that doesn't mean that the code changes are being correctly tested. In fact what is really interesting are the cases when the test that one would expect to break still passes, and another one (originally not related) is the one that fails. This either means that the fix was done in the wrong location, or that the impact of the change is happening at a different place (with both scenarios requiring further investigation).

Another sign that something is not right, is when simple code changes that should require simple test changes, do actually require considerable time to make the fix the tests that broke. What this means is that the tests are currently fragile and a refactoring (of the tests) is needed.

The reality is that making code changes without Tests is equivalent to making random changes and hoping that one of them does actually have the expected result, with the 'hope' that there are no major side effects. These 'non detected during development' side-effects (major or minor) will eventually affect the end-users, who will report a bug, which will be allocated for fix, which when coded will not be fully tested, which will create more 'non detected during development' side-effects , and, what we have in the end is the non-ending bug parade that affects most applications these days

### Code Coverage changes are part of the test success criteria

Broken tests are a great signal of side-effects of code changes, but an even better metric is changes in code coverage.

One of the reasons why 100% code coverage is so important, is because it provides accurate feedback on the impact of code changes. The lower the code coverage percentage, the harder it is to understand and review what happened with the latest commits.

Ideally, 100% code coverage should be one of the success criteria for Continuous Delivery.

### Git commits should only have the code and tests for the worked issue

One of the powers of git is its ability to allow the user merging the Pull Requests (PRs) to require quality and focus from the user submitting the changes.

This means that instead of massive Git Commits and PRs, that are just about impossible to read, what should happen is clean and focused PRs which should contain the code and respective tests.

### Performing code reviews by reading the tests first

One of the great side effects of having code and test submitted in the same Pull Request (PR) is that it allows the review process to occur not by reading the code first and then the tests, but by reading the tests first.

What happens when the tests are read first, is that the reviewed builds a mental model of the code changes that are expected to occur. What is interesting is what happens when the code changes don't match the tests changes.

This could happen because there is not enough test coverable, which means that random changes where made

It could be because the tests are to fragile and there were too many tests changes when compared with the actual code changes.

Or it could be that the existing tests are not good enough, and the tests need improvement.

Just because a test needed to be changed, that doesn't mean that the code changes are being correctly tested. These reviews are an important part of ensuring the high quality of code and tests.

### Clicking is an ephemeral tests

A significant amount of time is spent by developers, QA and managers in clicking on links and buttons.

All these clicks are of course tests. The problem is that they are ephemeral and disappear after each click.

The power of Tests is that they are not only automatically repeatable, they can be scheduled to occur at regular intervals and more importantly they will all execute (vs the human tester which will tend on only check/click on the perceived locations of the latests changes).

A good example is are the hundreds of permutations that occur on an user login system, where just the password recovery workflow requires dozens for highly specific Tests.

### How much time of your life have you spent on checking your code changes

For example logging in into a site or staring an application.

What is shocking, is that even though the actually coverage and effectiveness of the checks done to code changes made is really low, those checks take significant amount of time to perform.

Here is a typical workflow of such development practices:

- make change to source code file
- save it (some IDE do this automatically)
- compile it (some IDEs and languages don't require this)
- deploy to test server (which ranges from automatically to minutes)
- move mouse to open browser
- go to page that has the change made and get it into the correct state (this can be a simple browser refresh, or might require multiple steps)
- trigger the changed behavior (created by the code change
- go back to the IDE, and start again

Even when some of this happens automatically due to the chosen IDE or technology, the developer will need to switch context and will lose the mental models created during development.

This means that even if this loop takes 20 secs (which is not that realistic, since this regularly  take minutes), the impact to the developer's concentration level is significant.

{note:find reference from Deep Work book on the name of these 'non measured costs'}

### Change of context, humans are not good at it

When a developer has to move focus from development (i.e. it's IDE), the productivity loss it much greater than the duration of that interruption.

These interruptions (maybe a colleague asking a question, an email that just arrived in the inbox or the execution of a manual test) result in the developer's mind needing to switch context, which is scientifically proven that we humans are not very good at.

The concept of Deep Work (add book reference) is about the power that occurs when we are able to work continuously with high focus. Another analogy is when a developer is in the 'zone'

When programing there are number of models and data that is uploaded to the developer's brain. These models represent the current code behavior and the desired changes. The more complex the application (or code change) the longer it takes to reach a state where the problem is correctly understood and changes visualized.

Changing context will impact these mental models and require their rebuild (after coming back to the code).

When developers need to manually test their code changes, the productivity impact is enormous.

It is recommended that for projects with weak Test infrastructure, the RISK 'Lack of tests makes the developers 20% inefficient' is added and marked to be accepted by the technical architect and business owner)

### A key requirement for Test infrastructure is to make developers productive

An effective test infrastructure and architecture has to be focused on making the developers more productive, code faster, refactor faster and replace IDE debugging as way to debug issues.

By making the developers more productive, we create an environment where developers will write the tests themselves. Not because they are being 'forced to', but because they have learned that those tests save them time, and allows them to deploy with confidence.

### 100% code coverage should be an effortless side-effect of development

When developers have real-time test execution and code coverage on the IDE, 100% code coverage will be an side-effect of code.

When developers can see exactly what code paths are being executed (and what data reaches what code), the idea that code changes should not be tested becomes a weird occurrence, since no developer will write code is not checked (in one way or another)

### Measure how much time developers actually spend coding

A good way to measure across teams their current efficiency level (and test productivity), is to look at how much time the developers actually spend on coding

### Measure how many Pull Requests are sent across teams

### Code debugging is a sign of bad Test technology

### Feeding test execution data to ELK and visualizing it in real time

### Working from home or in isolation is key for development

### Measuring release's stress

The level of stress, issues, events, fixes and time that releases take, is a great bechmark for the quality of the code and tests.

If the team ships on a Wednesday, and key members of the team need to be on call to deal with the regular issues that occur due to that release, then you have a problem with that team.

Not only deployments should occur everyday (or hour), they should have no side affects, and in the rare case when they need to be reset, the revert process should be smooth, fast and effective.

The faster the deployment, the smaller the change and the easier it is to refactor the application.

The easier it is to refactor the application, the easier it is to address code quality and security issues.

The team that is able to push into production on a Friday afternoon with full confidence that nobody is going to have to stay behind to clean up the mess, is the team that has been shipping code all week (into dev, qa, pre-prod) and knows that their changes work with production data

Measuring deployment stress is then a great way to identify the teams that need help in their test infrastructure and setup (which is one of the areas where DevOps make a massive difference)

### Writing non-tested code is cheaper in the short-term

It is import not to sugarcoat this. The reality is that in the short term, it is indeed cheaper and simpler to: _just make the change and we'll add the test later_ (which never really happens)

The weaker the test infrastructure (when it is hard to write tests) the more expensive and complicated it is to make changes that are fully tested.

It is important to take into account that in such environment, ever though it is highly inefficient for developers to write code without tests (when compared to writing with tests), it is still cheaper, when compared with the effort to having to figure out how to test a particular part of the code

This means that the reason developers don't write tests, is not because they don't want to, it is because at that moment in time, they would be required to resolve key components of the test infrastructure (for example: how to get to page XYZ, how to simulate a particular service, how to deal with inner framework calls which depend on objects that are harder to access)

The problem is that in the medium and long term, these short terms gains are more than lost by customer impact of bugs created, and effort required to fix them.

### Don't use main, use a test

### When the users tell you what you code did

### Story: One char that broke the sites

Tell story

### Story: Site that worked on QA, Pre and not live

Todo-Note:
 - find 'Making random changes' quote
